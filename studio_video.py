import os
from dataclasses import dataclass
from typing import List, Optional

import cv2
import numpy as np

from core import gaussian_blur_region, expand_box
from detect import load_yolov5, detect_faces_yolov5
from face_registry import FaceRegistry
from face_embedder import get_embedding


# ----------------------------------
# ì „ì—­ ì„¤ì •
# ----------------------------------
YOLOV5_WEIGHTS = os.path.join(os.path.dirname(__file__), "best.pt")
DETECT_THUMB_W = 640
FACE_PAD = 0.05  # ì–¼êµ´ ì£¼ë³€ ì—¬ìœ  íŒ¨ë”© ë¹„ìœ¨ì´ë‹¤.

EMOJI_DIR = os.path.join(os.path.dirname(__file__), "emoji")

_DETECTOR = None  # YOLO ëª¨ë¸ ì „ì—­ ìºì‹œì´ë‹¤.


# ----------------------------------
# ë°ì´í„° í´ë˜ìŠ¤
# ----------------------------------
@dataclass
class FaceBox:
    x: int
    y: int
    w: int
    h: int
    identity: Optional[str] = None  # ë§¤ì¹­ëœ ì´ë¦„(ë“±ë¡ ì–¼êµ´ì´ë©´ ì´ë¦„), ì—†ìœ¼ë©´ Noneì´ë‹¤.
    emb: Optional[np.ndarray] = None  # ì–¼êµ´ ì„ë² ë”© ìºì‹œì´ë‹¤.


# ----------------------------------
# ë‚´ë¶€ ìœ í‹¸ í•¨ìˆ˜ë“¤
# ----------------------------------
def _get_detector():
    """YOLOv5 ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œí•´ì„œ ì¬ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤."""
    global _DETECTOR
    if _DETECTOR is None:
        _DETECTOR = load_yolov5(YOLOV5_WEIGHTS)
    return _DETECTOR


def _detect_on_frame(detector, frame) -> List[FaceBox]:
    """
    ë‹¨ì¼ í”„ë ˆì„ì—ì„œ ì–¼êµ´ì„ íƒì§€í•´ì„œ FaceBox ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.
    detect_faces_yolov5 ë°˜í™˜ í˜•ì‹ì— ë”°ë¼ x1,y1,x2,y2 ë˜ëŠ” x,y,w,h ë¥¼ ì²˜ë¦¬í•œë‹¤.
    """
    
    h, w = frame.shape[:2]
    boxes: List[FaceBox] = []

    # ğŸ”¥ ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ì´ë‹¤.
    # 1ì°¨ë¡œëŠ” 3ë²ˆì§¸ ì¸ìë¥¼ í¬ì§€ì…”ë„ë¡œ ë„£ì–´ë³´ê³ ,
    # TypeErrorê°€ ë‚˜ë©´ 2ì¸ì ë²„ì „ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•œë‹¤.
    try:
        detections = detect_faces_yolov5(detector, frame, DETECT_THUMB_W)
    except TypeError:
        detections = detect_faces_yolov5(detector, frame)

    faces: List[FaceBox] = []
    for (x, y, w, h) in detections:
        faces.append(FaceBox(x=x, y=y, w=w, h=h))

    print(f"[VIDEO_DETECT] faces={len(faces)}", flush=True)

    return faces

    if detections is None:
        return boxes

    for det in detections:
        # det í˜•ì‹ì´ [x1, y1, x2, y2, (score...)] ì´ê±°ë‚˜ [x, y, w, h] ë¼ê³  ê°€ì •í•œë‹¤.
        if len(det) >= 4:
            x1, y1, x2, y2 = det[0], det[1], det[2], det[3]

            # í˜¹ì‹œ (x, y, w, h) í˜•ì‹ì´ë©´ x2,y2 ë³€í™˜
            if x2 <= 1.0 and y2 <= 1.0:
                # 0~1 ì •ê·œí™” ì¢Œí‘œë¼ê³  ê°€ì •
                x1 = int(x1 * w)
                y1 = int(y1 * h)
                x2 = int(x2 * w)
                y2 = int(y2 * h)
            elif x2 < w and y2 < h and x2 - x1 > 0 and y2 - y1 > 0:
                # ì´ë¯¸ í”½ì…€ ì¢Œí‘œë¼ê³  ë³´ê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤.
                x1 = int(x1)
                y1 = int(y1)
                x2 = int(x2)
                y2 = int(y2)
            else:
                # ë‹¤ë¥¸ í˜•ì‹ì´ë©´ (x, y, w, h)ë¼ê³  ë³´ê³  ì²˜ë¦¬í•œë‹¤.
                x = int(det[0])
                y = int(det[1])
                ww = int(det[2])
                hh = int(det[3])
                x1, y1, x2, y2 = x, y, x + ww, y + hh

            x1 = max(0, min(w - 1, x1))
            y1 = max(0, min(h - 1, y1))
            x2 = max(0, min(w, x2))
            y2 = max(0, min(h, y2))
            bw = max(0, x2 - x1)
            bh = max(0, y2 - y1)

            if bw <= 0 or bh <= 0:
                continue

            boxes.append(FaceBox(x=x1, y=y1, w=bw, h=bh))

    return boxes



def _crop_face_with_pad(frame, box: FaceBox) -> Optional[np.ndarray]:
    """
    FACE_PAD ë¹„ìœ¨ë§Œí¼ í™•ì¥ëœ ì˜ì—­ìœ¼ë¡œ ì–¼êµ´ì„ ì˜ë¼ë‚´ì„œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.
    """
    h, w = frame.shape[:2]
    x, y, bw, bh = expand_box(box.x, box.y, box.w, box.h, FACE_PAD)

    x = max(0, min(w - 1, x))
    y = max(0, min(h - 1, y))
    x2 = max(0, min(w, x + bw))
    y2 = max(0, min(h, y + bh))

    bw = x2 - x
    bh = y2 - y
    if bw <= 0 or bh <= 0:
        return None

    return frame[y:y2, x:x2]


def _annotate_authorized_faces(registry: FaceRegistry, faces: List[FaceBox], frame):
    """
    FaceRegistryë¥¼ ì´ìš©í•´ ê° FaceBoxì— identity ë¥¼ ì±„ì›Œ ë„£ëŠ” í•¨ìˆ˜ì´ë‹¤.
    auth_exclude_enable ì´ Trueì¼ ë•Œë§Œ í˜¸ì¶œí•˜ë©´ ëœë‹¤.
    """
    for box in faces:
        crop = _crop_face_with_pad(frame, box)
        if crop is None:
            continue

        try:
            emb = get_embedding(crop)
        except Exception:
            emb = None

        if emb is None:
            continue

        box.emb = emb

        try:
            name, dist = registry.match(emb)
        except Exception:
            name, dist = None, None

        box.identity = name


def _should_blur_auto_face(
    registry: FaceRegistry,
    box: FaceBox,
    auth_exclude_enable: bool,
) -> bool:
    """
    ì–´ë–¤ ì–¼êµ´ì„ ë¸”ëŸ¬/ëª¨ìì´í¬ í• ì§€ ê²°ì •í•˜ëŠ” ì •ì±… í•¨ìˆ˜ì´ë‹¤.

    - auth_exclude_enable == False ì´ë©´: ëª¨ë“  ì–¼êµ´ì„ ë¸”ëŸ¬ ì²˜ë¦¬í•œë‹¤.
    - auth_exclude_enable == True ì´ë©´:
        box.identity ê°€ ì¡´ì¬í•˜ë©´ "ë“±ë¡ëœ ì–¼êµ´" ì´ë¼ê³  ë³´ê³  ëª¨ìì´í¬ì—ì„œ ì œì™¸í•œë‹¤.
    """
    if not auth_exclude_enable:
        return True

    # ê°„ë‹¨í•œ ì •ì±…: ë“±ë¡ëœ ì–¼êµ´(identityê°€ ìˆëŠ” ê²½ìš°)ì€ ì œì™¸í•œë‹¤.
    if box.identity:
        return False

    return True


def _load_emoji_image(emoji_path: Optional[str], emoji_index: int) -> Optional[np.ndarray]:
    """
    ì´ëª¨ì§€ ì´ë¯¸ì§€ë¥¼ ì½ì–´ì„œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.
    - emoji_path ê°€ ì£¼ì–´ì§€ë©´ ê·¸ ê²½ë¡œë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.
    - ì•„ë‹ˆë©´ EMOJI_DIR/emoji_{index}.png í˜•ì‹ìœ¼ë¡œ ì°¾ëŠ”ë‹¤.
    """
    candidate_paths = []

    if emoji_path:
        candidate_paths.append(emoji_path)

    # ê¸°ë³¸ ê²½ë¡œ: emoji_0.png, emoji_1.png ë“±ì˜ ì´ë¦„ì„ ê°€ì •í•œë‹¤.
    filename = f"emoji_{emoji_index}.png"
    candidate_paths.append(os.path.join(EMOJI_DIR, filename))

    for path in candidate_paths:
        if os.path.exists(path):
            img = cv2.imread(path, cv2.IMREAD_UNCHANGED)
            if img is not None:
                return img

    return None


def _overlay_emoji(
    frame: np.ndarray,
    x: int,
    y: int,
    w: int,
    h: int,
    emoji_img: Optional[np.ndarray],
):
    """ì–¼êµ´ ì˜ì—­ ìœ„ì— ì´ëª¨ì§€ ì´ë¯¸ì§€ë¥¼ ë®ì–´ì“°ëŠ” í•¨ìˆ˜ì´ë‹¤."""
    if emoji_img is None:
        return

    fh, fw = frame.shape[:2]

    x = max(0, min(fw - 1, x))
    y = max(0, min(fh - 1, y))
    x2 = max(0, min(fw, x + w))
    y2 = max(0, min(fh, y + h))

    w = x2 - x
    h = y2 - y
    if w <= 0 or h <= 0:
        return

    # ì´ëª¨ì§€ë¥¼ ì–¼êµ´ í¬ê¸°ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ
    emoji_resized = cv2.resize(emoji_img, (w, h), interpolation=cv2.INTER_AREA)

    if emoji_resized.shape[2] == 4:
        # RGBA (ì•ŒíŒŒ í¬í•¨) ì´ë©´ ì•ŒíŒŒ ë¸”ë Œë”©
        emoji_rgb = emoji_resized[:, :, :3]
        alpha = emoji_resized[:, :, 3:] / 255.0

        roi = frame[y:y2, x:x2]
        if roi.shape[:2] != emoji_rgb.shape[:2]:
            # í˜¹ì‹œ í¬ê¸° ì•ˆ ë§ìœ¼ë©´ í•œ ë²ˆ ë” ë§ì¶°ì¤€ë‹¤.
            emoji_rgb = cv2.resize(emoji_rgb, (roi.shape[1], roi.shape[0]))
            alpha = cv2.resize(alpha, (roi.shape[1], roi.shape[0]))

        frame[y:y2, x:x2] = (alpha * emoji_rgb + (1 - alpha) * roi).astype(
            np.uint8
        )
    else:
        # ì•ŒíŒŒê°€ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë®ì–´ì“°ê¸°
        frame[y:y2, x:x2] = emoji_resized[:, :, :3]


def _apply_mosaic(
    frame: np.ndarray,
    x: int,
    y: int,
    w: int,
    h: int,
    mosaic_size: int = 15,
):
    """ì–¼êµ´ ì˜ì—­ì— í”½ì…€ ëª¨ìì´í¬ë¥¼ ì ìš©í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤."""
    fh, fw = frame.shape[:2]

    x = max(0, min(fw - 1, x))
    y = max(0, min(fh - 1, y))
    x2 = max(0, min(fw, x + w))
    y2 = max(0, min(fh, y + h))

    w = x2 - x
    h = y2 - y
    if w <= 0 or h <= 0:
        return

    roi = frame[y:y2, x:x2]
    # ë„ˆë¬´ ì‘ì§€ ì•Šê²Œ ìµœì†Œ 1x1 ë³´ì¥
    small_w = max(1, w // mosaic_size)
    small_h = max(1, h // mosaic_size)

    small = cv2.resize(roi, (small_w, small_h), interpolation=cv2.INTER_LINEAR)
    mosaic = cv2.resize(small, (w, h), interpolation=cv2.INTER_NEAREST)
    frame[y:y2, x:x2] = mosaic

# ----------------------------------
# ë©”ì¸ ì—”íŠ¸ë¦¬: process_video
# ----------------------------------
def process_video(
    input_path: str,
    output_path: str,
    blur_strength: int,
    auth_exclude_enable: bool = False,
    style: str = "blur",
    emoji_path: Optional[str] = None,
    emoji_index: int = 0,
):
    """
    ì—…ë¡œë“œëœ ì˜ìƒ íŒŒì¼ì„ í”„ë ˆì„ ë‹¨ìœ„ë¡œ ì½ì–´,
    - ì–¼êµ´ì´ ì¡íˆë©´: ì–¼êµ´ ì˜ì—­ë§Œ blur/mosaic/emoji ì²˜ë¦¬
    - ì–¼êµ´ì´ í•˜ë‚˜ë„ ì•ˆ ì¡íˆë©´: í”„ë ˆì„ ì „ì²´ë¥¼ blur ì²˜ë¦¬í•œ ë’¤
      output_path ì— mp4 ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.
    """
    if not os.path.exists(input_path):
        raise FileNotFoundError(f"input video not found: {input_path}")

    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        raise RuntimeError(f"cannot open video: {input_path}")

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    if not fps or fps <= 1e-2:
        fps = 25.0  # FPS ì •ë³´ê°€ ê¹¨ì ¸ ìˆìœ¼ë©´ ê¸°ë³¸ê°’

    # ì¶œë ¥ ë¹„ë””ì˜¤ ì¤€ë¹„
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    # ì–¼êµ´ ë“±ë¡ ë ˆì§€ìŠ¤íŠ¸ë¦¬ (ë“±ë¡ ì–¼êµ´ ì œì™¸ ê¸°ëŠ¥ìš©)
    registry = FaceRegistry()

    # ì´ëª¨ì§€ ìŠ¤íƒ€ì¼ì´ë©´ ì´ëª¨ì§€ ì´ë¯¸ì§€ë¥¼ ë¯¸ë¦¬ ë¡œë“œ
    emoji_img = None
    if style == "emoji":
        emoji_img = _load_emoji_image(emoji_path, emoji_index)
        if emoji_img is None:
            # ì´ëª¨ì§€ ë¡œë”© ì‹¤íŒ¨ ì‹œ, ì•ˆì „í•˜ê²Œ blur ìŠ¤íƒ€ì¼ë¡œ ëŒ€ì²´
            style = "blur"

    detector = _get_detector()

    try:
        while True:
            ok, frame = cap.read()
            if not ok:
                break

            # ------------------------------
            # 1) ì–¼êµ´ íƒì§€
            # ------------------------------
            faces = _detect_on_frame(detector, frame)

            # ------------------------------
            # 2) ì–¼êµ´ì´ í•˜ë‚˜ë„ ì•ˆ ì¡íŒ ê²½ìš°:
            #    í”„ë ˆì„ ì „ì²´ë¥¼ ë¸”ëŸ¬ ì²˜ë¦¬
            # ------------------------------
            if not faces:
                gaussian_blur_region(
                    frame,
                    0,
                    0,
                    width,
                    height,
                    blur_strength,
                )
                writer.write(frame)
                continue

            # ------------------------------
            # 3) ë“±ë¡ ì–¼êµ´/ì •ì±… ë°˜ì˜
            # ------------------------------
            if auth_exclude_enable:
                _annotate_authorized_faces(registry, faces, frame)

            # ------------------------------
            # 4) ìŠ¤íƒ€ì¼ë³„ ì²˜ë¦¬
            # ------------------------------
            for box in faces:
                # ë“±ë¡ ì–¼êµ´ ë“±ìœ¼ë¡œ ëª¨ìì´í¬ ì œì™¸ ëŒ€ìƒì´ë©´ ê±´ë„ˆë›°ê¸°
                if not _should_blur_auto_face(registry, box, auth_exclude_enable):
                    continue

                if style == "blur":
                    gaussian_blur_region(
                        frame,
                        box.x,
                        box.y,
                        box.w,
                        box.h,
                        blur_strength,
                    )

                elif style == "mosaic":
                    _apply_mosaic(
                        frame,
                        box.x,
                        box.y,
                        box.w,
                        box.h,
                        mosaic_size=max(8, min(30, int(blur_strength))),
                    )

                elif style == "emoji":
                    _overlay_emoji(frame, box.x, box.y, box.w, box.h, emoji_img)

                else:
                    # ì•Œ ìˆ˜ ì—†ëŠ” ìŠ¤íƒ€ì¼ì´ë©´ ê¸°ë³¸ì ìœ¼ë¡œ blur
                    gaussian_blur_region(
                        frame,
                        box.x,
                        box.y,
                        box.w,
                        box.h,
                        blur_strength,
                    )

            # í•œ í”„ë ˆì„ ìµœì¢… ê²°ê³¼ ì“°ê¸°
            writer.write(frame)

    finally:
        cap.release()
        writer.release()

